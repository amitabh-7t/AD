{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 9: Model Evaluation\n",
        "\n",
        "Compute comprehensive metrics, confusion matrices, and ROC curves for all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: 1762 images, 4 classes\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, roc_curve, auc,\n",
        "    balanced_accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import json\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = '../outputs/evaluation'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "test_df = pd.read_csv('../outputs/test_manifest.csv')\n",
        "classes = sorted(test_df['class_name'].unique())\n",
        "print(f'Test set: {len(test_df)} images, {len(classes)} classes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Custom Label Smoothing Loss (Needed for loading models)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class LabelSmoothingLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, num_classes=4, smoothing=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.smoothing = smoothing\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'num_classes': self.num_classes, 'smoothing': self.smoothing})\n",
        "        return config\n",
        "        \n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, self.num_classes)\n",
        "        y_true_smooth = y_true_one_hot * (1 - self.smoothing) + self.smoothing / self.num_classes\n",
        "        return tf.keras.losses.categorical_crossentropy(y_true_smooth, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Test dataset created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-01 20:36:23.991574: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
            "2026-02-01 20:36:23.991620: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2026-02-01 20:36:23.991630: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
            "2026-02-01 20:36:23.991670: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2026-02-01 20:36:23.991681: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess(filepath, label):\n",
        "    img = tf.io.read_file(filepath)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img / 255.0, label\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    test_df['filepath'].values,\n",
        "    test_df['class_label'].values\n",
        "))\n",
        "test_ds = test_ds.map(preprocess, tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "print('✓ Test dataset created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️  Model not found: ../outputs/models/baseline_cnn_best.h5\n",
            "⚠️  Model not found: ../outputs/models/resnet50_best.h5\n",
            "⚠️  Model not found: ../outputs/models/resnet50_attention_best.h5\n",
            "⚠️  Model not found: ../outputs/models/efficientnetb0_best.h5\n",
            "\n",
            "============================================================\n",
            "⚠️  NO MODELS FOUND FOR EVALUATION\n",
            "============================================================\n",
            "\n",
            "Please train models first using notebooks 05, 06, 06b, and 07\n",
            "Models should be saved in: ../outputs/models/\n"
          ]
        }
      ],
      "source": [
        "models = ['baseline_cnn', 'resnet50', 'resnet50_attention', 'efficientnetb0']\n",
        "results = []\n",
        "\n",
        "for model_name in models:\n",
        "    model_path = f'../outputs/models/{model_name}_best.h5'\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f'⚠️  Model not found: {model_path}')\n",
        "        continue\n",
        "    \n",
        "    print(f'\\nEvaluating {model_name}...')\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects={'LabelSmoothingLoss': LabelSmoothingLoss, 'label_smoothing_loss': LabelSmoothingLoss})\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_probs = model.predict(test_ds)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = test_df['class_label'].values\n",
        "    \n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred, zero_division=0)\n",
        "    \n",
        "    macro_f1 = np.mean(f1)\n",
        "    weighted_f1 = np.average(f1, weights=s)\n",
        "    \n",
        "    results.append({\n",
        "        'model': model_name,\n",
        "        'accuracy': acc,\n",
        "        'balanced_accuracy': bal_acc,\n",
        "        'macro_f1': macro_f1,\n",
        "        'weighted_f1': weighted_f1\n",
        "    })\n",
        "    \n",
        "    print(f'  Accuracy: {acc:.4f}')\n",
        "    print(f'  Balanced Accuracy: {bal_acc:.4f}')\n",
        "    print(f'  Macro F1: {macro_f1:.4f}')\n",
        "    \n",
        "    # Save predictions\n",
        "    pred_df = test_df.copy()\n",
        "    pred_df['predicted_label'] = y_pred\n",
        "    pred_df['is_correct'] = y_true == y_pred\n",
        "    for i, cn in enumerate(classes):\n",
        "        pred_df[f'prob_{cn.replace(\" \", \"_\")}'] = y_pred_probs[:, i]\n",
        "    pred_df.to_csv(f'{OUTPUT_DIR}/{model_name}_predictions.csv', index=False)\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "               xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f'{model_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{OUTPUT_DIR}/{model_name}_confusion_matrix.png', dpi=200)\n",
        "    plt.show()\n",
        "    \n",
        "    # ROC curves\n",
        "    y_bin = label_binarize(y_true, classes=list(range(len(classes))))\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i, cn in enumerate(classes):\n",
        "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_pred_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{cn} (AUC={roc_auc:.3f})', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} - ROC Curves', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{OUTPUT_DIR}/{model_name}_roc_curves.png', dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "if len(results) > 0:\n",
        "    results_df = pd.DataFrame(results).sort_values('macro_f1', ascending=False)\n",
        "    results_df.to_csv(f'{OUTPUT_DIR}/all_models_metrics.csv', index=False)\n",
        "    print('\\n' + '='*60)\n",
        "    print('✅ EVALUATION COMPLETE')\n",
        "    print('='*60)\n",
        "    print('\\nModel Rankings by Macro F1:')\n",
        "    print(results_df)\n",
        "else:\n",
        "    print('\\n' + '='*60)\n",
        "    print('⚠️  NO MODELS FOUND FOR EVALUATION')\n",
        "    print('='*60)\n",
        "    print('\\nPlease train models first using notebooks 05, 06, 06b, and 07')\n",
        "    print('Models should be saved in: ../outputs/models/')\n",
        "    # Create empty results file\n",
        "    empty_df = pd.DataFrame(columns=['model', 'accuracy', 'balanced_accuracy', 'macro_f1', 'weighted_f1'])\n",
        "    empty_df.to_csv(f'{OUTPUT_DIR}/all_models_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
