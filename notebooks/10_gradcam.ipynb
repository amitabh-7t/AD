{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 10: Grad-CAM Explainability\n",
        "\n",
        "Visualize what regions of the image the models focus on using Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Setup complete\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = '../outputs/gradcam'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print('✓ Setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Custom Label Smoothing Loss (Needed for loading models)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class LabelSmoothingLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, num_classes=4, smoothing=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.smoothing = smoothing\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'num_classes': self.num_classes, 'smoothing': self.smoothing})\n",
        "        return config\n",
        "        \n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, self.num_classes)\n",
        "        y_true_smooth = y_true_one_hot * (1 - self.smoothing) + self.smoothing / self.num_classes\n",
        "        return tf.keras.losses.categorical_crossentropy(y_true_smooth, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grad-CAM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Grad-CAM functions defined\n"
          ]
        }
      ],
      "source": [
        "def find_last_conv_layer(model):\n",
        "    \"\"\"Find the last convolutional layer in the model.\"\"\"\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            return layer.name\n",
        "        # Check if it's a nested model\n",
        "        if hasattr(layer, 'layers'):\n",
        "            for sublayer in reversed(layer.layers):\n",
        "                if isinstance(sublayer, tf.keras.layers.Conv2D):\n",
        "                    return sublayer.name\n",
        "    raise ValueError('No Conv2D layer found')\n",
        "\n",
        "def generate_gradcam(img_array, model, conv_layer_name, pred_index=None):\n",
        "    \"\"\"Generate Grad-CAM heatmap.\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(conv_layer_name).output, model.output]\n",
        "    )\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    \n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    \n",
        "    return heatmap.numpy()\n",
        "\n",
        "print('✓ Grad-CAM functions defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Heatmaps for All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating Grad-CAM for baseline_cnn...\n",
            "  Last conv layer: conv2d_3\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "The layer sequential_1 has never been called and thus has no defined output.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Generate heatmap\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create overlay\u001b[39;00m\n\u001b[1;32m     39\u001b[0m original \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n",
            "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mgenerate_gradcam\u001b[0;34m(img_array, model, conv_layer_name, pred_index)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_gradcam\u001b[39m(img_array, model, conv_layer_name, pred_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate Grad-CAM heatmap.\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     grad_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m     16\u001b[0m         [model\u001b[38;5;241m.\u001b[39minputs],\n\u001b[0;32m---> 17\u001b[0m         [model\u001b[38;5;241m.\u001b[39mget_layer(conv_layer_name)\u001b[38;5;241m.\u001b[39moutput, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m]\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     21\u001b[0m         conv_outputs, predictions \u001b[38;5;241m=\u001b[39m grad_model(img_array)\n",
            "File \u001b[0;32m~/Workspace/Projects/ML/AD/venv/lib/python3.10/site-packages/keras/src/ops/operation.py:349\u001b[0m, in \u001b[0;36mOperation.output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moutput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m        Output tensor or list of output tensors.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Workspace/Projects/ML/AD/venv/lib/python3.10/site-packages/keras/src/ops/operation.py:368\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential_1 has never been called and thus has no defined output."
          ]
        }
      ],
      "source": [
        "test_df = pd.read_csv('../outputs/test_manifest.csv')\n",
        "classes = sorted(test_df['class_name'].unique())\n",
        "models = ['baseline_cnn', 'resnet50', 'resnet50_attention', 'efficientnetb0']\n",
        "\n",
        "for model_name in models:\n",
        "    model_path = f'../outputs/models/{model_name}_best.h5'\n",
        "    if not os.path.exists(model_path):\n",
        "        continue\n",
        "    \n",
        "    print(f'\\nGenerating Grad-CAM for {model_name}...')\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects={'LabelSmoothingLoss': LabelSmoothingLoss, 'label_smoothing_loss': LabelSmoothingLoss})\n",
        "    try:\n",
        "        conv_layer = find_last_conv_layer(model)\n",
        "        print(f'  Last conv layer: {conv_layer}')\n",
        "    except ValueError as e:\n",
        "        print(f'  ⚠️  {e}')\n",
        "        continue\n",
        "    \n",
        "    model_dir = f'{OUTPUT_DIR}/{model_name}'\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    \n",
        "    # Generate for 5 samples per class\n",
        "    for class_name in classes:\n",
        "        class_samples = test_df[test_df['class_name'] == class_name].sample(\n",
        "            n=min(5, len(test_df[test_df['class_name'] == class_name])),\n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        for idx, (_, row) in enumerate(class_samples.iterrows()):\n",
        "            # Load image\n",
        "            img = tf.keras.preprocessing.image.load_img(row['filepath'], target_size=(224, 224))\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array / 255.0, axis=0)\n",
        "            \n",
        "            # Generate heatmap\n",
        "            heatmap = generate_gradcam(img_array, model, conv_layer)\n",
        "            \n",
        "            # Create overlay\n",
        "            original = np.array(img)\n",
        "            heatmap_resized = np.uint8(255 * heatmap)\n",
        "            heatmap_resized = Image.fromarray(heatmap_resized).resize((original.shape[1], original.shape[0]))\n",
        "            heatmap_resized = np.array(heatmap_resized)\n",
        "            \n",
        "            jet = cm.get_cmap('jet')\n",
        "            jet_heatmap = jet(heatmap_resized)[:, :, :3]\n",
        "            jet_heatmap = np.uint8(255 * jet_heatmap)\n",
        "            overlay = np.uint8(jet_heatmap * 0.4 + original * 0.6)\n",
        "            \n",
        "            # Save visualization\n",
        "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            ax1.imshow(original)\n",
        "            ax1.set_title('Original')\n",
        "            ax1.axis('off')\n",
        "            ax2.imshow(heatmap_resized, cmap='jet')\n",
        "            ax2.set_title('Heatmap')\n",
        "            ax2.axis('off')\n",
        "            ax3.imshow(overlay)\n",
        "            ax3.set_title('Overlay')\n",
        "            ax3.axis('off')\n",
        "            plt.suptitle(f'{class_name}', fontsize=12, fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{model_dir}/{class_name.replace(\" \", \"_\")}_sample{idx}.png', dpi=150)\n",
        "            plt.close()\n",
        "    \n",
        "    print(f'  ✓ Saved Grad-CAM visualizations to {model_dir}/')\n",
        "\n",
        "print('\\n✅ GRAD-CAM COMPLETE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
