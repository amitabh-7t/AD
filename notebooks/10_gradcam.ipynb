{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 10: Grad-CAM Explainability\n",
        "\n",
        "Visualize what regions of the image the models focus on using Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Setup complete\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = '../outputs/gradcam'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print('✓ Setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Custom Label Smoothing Loss (Needed for loading models)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class LabelSmoothingLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, num_classes=4, smoothing=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.smoothing = smoothing\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'num_classes': self.num_classes, 'smoothing': self.smoothing})\n",
        "        return config\n",
        "        \n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, self.num_classes)\n",
        "        y_true_smooth = y_true_one_hot * (1 - self.smoothing) + self.smoothing / self.num_classes\n",
        "        return tf.keras.losses.categorical_crossentropy(y_true_smooth, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grad-CAM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Grad-CAM functions defined\n"
          ]
        }
      ],
      "source": [
        "def find_last_conv_layer(model):\n",
        "    \"\"\"Find the last convolutional layer in the model.\"\"\"\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            return layer.name\n",
        "        # Check if it's a nested model\n",
        "        if hasattr(layer, 'layers'):\n",
        "            for sublayer in reversed(layer.layers):\n",
        "                if isinstance(sublayer, tf.keras.layers.Conv2D):\n",
        "                    return sublayer.name\n",
        "    raise ValueError('No Conv2D layer found')\n",
        "\n",
        "def generate_gradcam(img_array, model, conv_layer_name, pred_index=None):\n",
        "    \"\"\"Generate Grad-CAM heatmap.\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(conv_layer_name).output, model.output]\n",
        "    )\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    \n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    \n",
        "    return heatmap.numpy()\n",
        "\n",
        "print('✓ Grad-CAM functions defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Heatmaps for All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️  Model not found: ../outputs/models/baseline_cnn_best.h5\n",
            "⚠️  Model not found: ../outputs/models/resnet50_best.h5\n",
            "⚠️  Model not found: ../outputs/models/resnet50_attention_best.h5\n",
            "⚠️  Model not found: ../outputs/models/efficientnetb0_best.h5\n",
            "\n",
            "⚠️  NO MODELS FOUND - Please train models first (notebooks 05, 06, 06b, 07)\n"
          ]
        }
      ],
      "source": [
        "test_df = pd.read_csv('../outputs/test_manifest.csv')\n",
        "classes = sorted(test_df['class_name'].unique())\n",
        "models = ['baseline_cnn', 'resnet50', 'resnet50_attention', 'efficientnetb0']\n",
        "\n",
        "models_processed = 0\n",
        "for model_name in models:\n",
        "    model_path = f'../outputs/models/{model_name}_best.h5'\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f'⚠️  Model not found: {model_path}')\n",
        "        continue\n",
        "    \n",
        "    print(f'\\nGenerating Grad-CAM for {model_name}...')\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects={'LabelSmoothingLoss': LabelSmoothingLoss, 'label_smoothing_loss': LabelSmoothingLoss})\n",
        "    try:\n",
        "        conv_layer = find_last_conv_layer(model)\n",
        "        print(f'  Last conv layer: {conv_layer}')\n",
        "    except ValueError as e:\n",
        "        print(f'  ⚠️  {e}')\n",
        "        continue\n",
        "    \n",
        "    model_dir = f'{OUTPUT_DIR}/{model_name}'\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    \n",
        "    # Generate for 5 samples per class\n",
        "    for class_name in classes:\n",
        "        class_samples = test_df[test_df['class_name'] == class_name].sample(\n",
        "            n=min(5, len(test_df[test_df['class_name'] == class_name])),\n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        for idx, (_, row) in enumerate(class_samples.iterrows()):\n",
        "            # Load image\n",
        "            img = tf.keras.preprocessing.image.load_img(row['filepath'], target_size=(224, 224))\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array / 255.0, axis=0)\n",
        "            \n",
        "            # Generate heatmap\n",
        "            heatmap = generate_gradcam(img_array, model, conv_layer)\n",
        "            \n",
        "            # Create overlay\n",
        "            original = np.array(img)\n",
        "            heatmap_resized = np.uint8(255 * heatmap)\n",
        "            heatmap_resized = Image.fromarray(heatmap_resized).resize((original.shape[1], original.shape[0]))\n",
        "            heatmap_resized = np.array(heatmap_resized)\n",
        "            \n",
        "            jet = cm.get_cmap('jet')\n",
        "            jet_heatmap = jet(heatmap_resized)[:, :, :3]\n",
        "            jet_heatmap = np.uint8(255 * jet_heatmap)\n",
        "            overlay = np.uint8(jet_heatmap * 0.4 + original * 0.6)\n",
        "            \n",
        "            # Save visualization\n",
        "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            ax1.imshow(original)\n",
        "            ax1.set_title('Original')\n",
        "            ax1.axis('off')\n",
        "            ax2.imshow(heatmap_resized, cmap='jet')\n",
        "            ax2.set_title('Heatmap')\n",
        "            ax2.axis('off')\n",
        "            ax3.imshow(overlay)\n",
        "            ax3.set_title('Overlay')\n",
        "            ax3.axis('off')\n",
        "            plt.suptitle(f'{class_name}', fontsize=12, fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{model_dir}/{class_name.replace(\" \", \"_\")}_sample{idx}.png', dpi=150)\n",
        "            plt.close()\n",
        "    \n",
        "    print(f'  ✓ Saved Grad-CAM visualizations to {model_dir}/')\n",
        "    models_processed += 1\n",
        "\n",
        "if models_processed > 0:\n",
        "    print(f'\\n✅ GRAD-CAM COMPLETE - Processed {models_processed} model(s)')\n",
        "else:\n",
        "    print('\\n⚠️  NO MODELS FOUND - Please train models first (notebooks 05, 06, 06b, 07)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
